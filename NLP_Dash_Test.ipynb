{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\583185\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py27\\lib\\site-packages\\gensim\\utils.py:860: UserWarning:\n",
      "\n",
      "detected Windows; aliasing chunkize to chunkize_serial\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Imports and setup for Jupyter\n",
    "\n",
    "import dash\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython import display\n",
    "import re\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk import corpus\n",
    "from nltk.collocations import *\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk import wordnet\n",
    "from nltk import punkt\n",
    "from nltk.util import ngrams\n",
    "from nltk import FreqDist\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "##function should allow to run in jupyter-- use show_app(#nameofapp) \n",
    "\n",
    "def show_app(app,  # type: dash.Dash\n",
    "             port=9999,\n",
    "             width=700,\n",
    "             height=900,\n",
    "             offline=True,\n",
    "             style=True,\n",
    "             **dash_flask_kwargs):\n",
    "    \"\"\"\n",
    "    Run the application inside a Jupyter notebook and show an iframe with it\n",
    "    :param app:\n",
    "    :param port:\n",
    "    :param width:\n",
    "    :param height:\n",
    "    :param offline:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    url = 'http://localhost:%d' % port\n",
    "    iframe = '<iframe src=\"{url}\" width={width} height={height}></iframe>'.format(url=url,\n",
    "                                                                                  width=width,\n",
    "                                                                                  height=height)\n",
    "    display.display_html(iframe, raw=True)\n",
    "    if offline:\n",
    "        app.css.config.serve_locally = True\n",
    "        app.scripts.config.serve_locally = True\n",
    "    if style:\n",
    "        external_css = [\"https://fonts.googleapis.com/css?family=Raleway:400,300,600\",\n",
    "                        \"https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\",\n",
    "                        \"http://getbootstrap.com/dist/css/bootstrap.min.css\", ]\n",
    "\n",
    "        for css in external_css:\n",
    "            app.css.append_css({\"external_url\": css})\n",
    "\n",
    "        external_js = [\"https://code.jquery.com/jquery-3.2.1.min.js\",\n",
    "                       \"https://cdn.rawgit.com/plotly/dash-app-stylesheets/a3401de132a6d0b652ba11548736b1d1e80aa10d/dash-goldman-sachs-report-js.js\",\n",
    "                       \"http://getbootstrap.com/dist/js/bootstrap.min.js\"]\n",
    "\n",
    "        for js in external_js:\n",
    "            app.scripts.append_script({\"external_url\": js})\n",
    "\n",
    "    return app.run_server(debug=False,  # needs to be false in Jupyter\n",
    "                          port=port,\n",
    "                          **dash_flask_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Dash Notes\n",
    "\n",
    "anything that starts with html. ... is generating pure HTML, anything that comes from the dcc. library is using things like Javascript, CSS and HTML\n",
    "\n",
    "can customize the CSS styles of the app---app.css.append_css()\n",
    "\n",
    "have to stop the kernal and restart each time you'd like to 'retest' the app--- guessing that it stays running so that you can make interactive changes to it.\n",
    "\n",
    "style property is best to supply a dictionary to (colors example)\n",
    "\n",
    "dcc.Graph renders interactive data viz using JavaScript graphing library.\n",
    "\n",
    "can write text in markdown... set something text equal to a variable and then use dcc.Markdown function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call backs (interactivity) notes\n",
    "\n",
    "need to import dash.depencies (input output)\n",
    "\n",
    "describe inputs and outputs through a app.callback decorator\n",
    "\n",
    "the inputs and outputs of the application are simply the properties of a particular component (so for example a dcc.Input)\n",
    "\n",
    "don't set a value for the children property of the my-div component in the layout... when Dash starts it automatically calls all of the callbacks with the inital values of the input components in order to population the initial start\n",
    "\n",
    "It's reactive programming\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\583185\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py27\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning:\n",
      "\n",
      "No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file C:\\Users\\583185\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py27\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Importing the final report\n",
    "\n",
    "##can I call something from another jupyter notebook? Seems like we might need to either have a massive setup beforehand or\n",
    "##save the other file as a .py script and then import like that\n",
    "\n",
    "report=pd.read_csv('connect_report.csv')\n",
    "\n",
    "report['Created Date']=pd.to_datetime(report['Created Date'])\n",
    "report=report[pd.notnull(report['Created Date'])]\n",
    "report=report[pd.notnull(report['Body'])]\n",
    "\n",
    "#Removing HTML tags and codes\n",
    "report['Body'] = report['Body'].apply(lambda x:BeautifulSoup(x))\n",
    "report['Body'] = report['Body'].apply(lambda x:x.get_text())\n",
    "\n",
    "#Removing tags/mentions\n",
    "report['Body'] = report['Body'].apply(lambda x:re.sub('{@[\\w\\d]*}', '',x))\n",
    "\n",
    "#Removing urls\n",
    "report['Body'] = report['Body'].apply(lambda x:re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', x,flags=re.MULTILINE))\n",
    "\n",
    "#Removing weird unicode characters\n",
    "report['Body'] = report['Body'].apply(lambda x: x.encode('ascii', 'ignore'))\n",
    "\n",
    "\n",
    "final_report=pd.DataFrame\n",
    "\n",
    "#Use this function to create the final report\n",
    "# Directions:\n",
    "# 1. Set Group to a list of group names, a single name of a group, or All to use all groups\n",
    "# 2. Set Type to a specific Feed Item Type or All\n",
    "# 3. Set Start Date or leave blank(defaults to: )\n",
    "# 4. Set End Date or leave blank(defaults to: )\n",
    "\n",
    "# def report_generator(Group,Type,Date_start=pd.to_datetime(\"2017-01-01\"),Date_finish=pd.to_datetime('today')):\n",
    "#     if type(Group) == list:\n",
    "#         final_report=report.loc[report['Name'].isin(Group)] \n",
    "#     elif (Group=='All'):\n",
    "#         final_report=report\n",
    "#     else:\n",
    "#         final_report=report.loc[report['Name']==Group]\n",
    "                                \n",
    "#     if (Type=='All'):\n",
    "#         final_report=final_report\n",
    "#     else:\n",
    "#         final_report=final_report.loc[final_report['Feed Item Type']==Type]\n",
    "    \n",
    "#     if(Date_start==\"2017-01-01\" and Date_finish== pd.to_datetime('today')):\n",
    "#         final_report=final_report\n",
    "#     else:\n",
    "#         Date_start=pd.to_datetime(Date_start, utc=False)\n",
    "#         Date_finish=pd.to_datetime(Date_finish, utc=False)\n",
    "#         #alt approach-- not working but not sure why-- it worked it worked it worked! had to change the data type to all be annoying ass datatime64... down the line that might be a pain but for now it's dope\n",
    "#         final_report=final_report[(final_report['Created Date'] > Date_start) & (final_report['Created Date']< Date_finish)]   \n",
    "#     return(final_report)\n",
    "\n",
    "# final_report=report_generator(['CPC+ All','NLT Internal Users'],'All',\"2017-02-01\",\"2017-03-01\")\n",
    "\n",
    "\n",
    "def report_generator(Group,Type):\n",
    "    if type(Group) == list:\n",
    "        final_report=report.loc[report['Name'].isin(Group)] \n",
    "    elif (Group=='All'):\n",
    "        final_report=report\n",
    "    else:\n",
    "        final_report=report.loc[report['Name']==Group]\n",
    "                                \n",
    "    if (Type=='All'):\n",
    "        final_report=final_report\n",
    "    else:\n",
    "        final_report=final_report.loc[final_report['Feed Item Type']==Type]     \n",
    "    return(final_report)\n",
    "\n",
    "final_report=report_generator(['CPC+ All','NLT Internal Users'],'All')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "stop.append(\"cpc+\")\n",
    "stop.append(\"hi\")\n",
    "stop.append(\"hello\")\n",
    "stop.append(\"also\")\n",
    "stop.append(\"anyone\")\n",
    "stop.append(\"et\")\n",
    "stop.append(\"please\")\n",
    "\n",
    "wnl = WordNetLemmatizer() \n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    " \n",
    "    tokens_ = [word_tokenize(sent) for sent in sent_tokenize(text.lower())]\n",
    "    \n",
    "    tokens = []\n",
    "    \n",
    "    for token_by_sent in tokens_:\n",
    "        tokens += token_by_sent\n",
    " \n",
    "    tokens = list(filter(lambda t: t not in stop, tokens))\n",
    "    tokens = list(filter(lambda t: t not in punctuation, tokens))\n",
    "    tokens = list(filter(lambda t: t not in [u\"'s\", u\"n't\",u\"'ve\",u\"'re\",u\"'d\",u\"'ll\",u\"'m\", u\"u\", \n",
    "                                             u\"...\", u\"''\", u'``', u'\\u2014', u'\\u2026', u'\\u2013'], tokens))\n",
    "     \n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        token = wnl.lemmatize(token)\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    " \n",
    "    filtered_tokens = list(map(lambda token: token.lower(), filtered_tokens))\n",
    "    \n",
    "    bigrm = nltk.bigrams(filtered_tokens)\n",
    "    bi_tokens = []\n",
    "    for a, b in bigrm:\n",
    "        bi_tok = ' '.join((a, b))\n",
    "        bi_tokens.append(bi_tok)\n",
    "    \n",
    "    filtered_tokens.extend(bi_tokens)\n",
    "    \n",
    "    return filtered_tokens\n",
    "\n",
    "def single_day_tracker(report):\n",
    "    #Create the top 10 list\n",
    "    unlisted_report=report['tokens'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "    word_vectorizer_2=CountVectorizer(ngram_range=(1,1), analyzer='word')\n",
    "    word_vectorizer_fit_2=word_vectorizer_2.fit_transform(unlisted_report)\n",
    "\n",
    "    frequencies=sum(word_vectorizer_fit_2).toarray()[0]\n",
    "\n",
    "    bigrams_counter=pd.DataFrame(frequencies,index=word_vectorizer_2.get_feature_names(),columns=['frequency'])\n",
    "    f = bigrams_counter[bigrams_counter['frequency']>10]\n",
    "    \n",
    "   \n",
    "    f=f.sort_values(by=['frequency'],ascending=False)\n",
    "    top_words=f.head(15)\n",
    "    \n",
    "    top_words_listed=list(top_words.index)\n",
    "\n",
    "\n",
    "    #Okay now figure out what the frequency was each day\n",
    "    unique_dates=set(report['Created Date'])\n",
    "    list_dates=sorted(list(unique_dates))\n",
    "    list_df_name=list(xrange(0,len(list_dates)))\n",
    "    list_df=[]\n",
    "    new_df=pd.DataFrame\n",
    "    for i in xrange(0,len(list_dates)):\n",
    "        date_report=report.loc[report['Created Date']==list_dates[i]]\n",
    "        unlisted_report_date=unlisted_report=date_report['tokens'].apply(lambda x: ', '.join(x))\n",
    "        word_vectorizer_fit_date=word_vectorizer_2.fit_transform(unlisted_report_date)\n",
    "        frequencies_date=sum(word_vectorizer_fit_date).toarray()[0]\n",
    "        bigrams_counter_date=pd.DataFrame(frequencies_date,index=word_vectorizer_2.get_feature_names(),columns=['frequency'])\n",
    "        bigrams_date_listed=list(bigrams_counter_date.index)\n",
    "        finder=(bigrams_counter_date.index.isin(top_words.index))\n",
    "        slimmed=(bigrams_counter_date[finder])\n",
    "        slimmed['word']=slimmed.index\n",
    "        slimmed['date']=list_dates[i]\n",
    "        slimmed['date']=pd.to_datetime(slimmed['date'])\n",
    "        list_df_name[i]=slimmed\n",
    "        list_df.append(list_df_name[i])\n",
    "    new_df=pd.concat(list_df)\n",
    "    new_df.index=xrange(0,len(new_df['word']))\n",
    "    return(new_df)\n",
    "\n",
    "##MOVED INTO REACTIVE SECTION BELOW\n",
    "            \n",
    "# top_words=single_day_tracker(final_report)\n",
    "\n",
    "\n",
    "    \n",
    "# #Bigrams/collocation scoring\n",
    "# bigram_measures=nltk.collocations.BigramAssocMeasures()\n",
    "# finder_2=BigramCollocationFinder.from_documents(final_report['tokens'])\n",
    "# score_collocation_2=finder_2.nbest(bigram_measures.pmi,5)\n",
    "\n",
    "# scored = finder_2.score_ngrams(bigram_measures.pmi)\n",
    "# sorted_scored=sorted(bigram for bigram, score in scored)\n",
    "\n",
    "\n",
    "\n",
    "#Single word finder\n",
    "def single_word_finder(x,y,mode='single'):\n",
    "    scores_e=list(enumerate(scored))\n",
    "    index_list=[]\n",
    "    final_list=[]\n",
    "    if(mode=='double'):\n",
    "        for i, v in enumerate(scored):\n",
    "            if v[0] == (x,y):\n",
    "                return scores_e[i]\n",
    "            elif v[0] == (y,x):\n",
    "                return scores_e[i]\n",
    "    elif(mode=='single'):\n",
    "        for i, v in enumerate(scored):\n",
    "            if(scores_e[i][1][0][0]) == x or scores_e[i][1][0][1] == x or scores_e[i][1][0][0]==y or scores_e[i][1][0][1]==y:\n",
    "                index_list.append(i)\n",
    "        for j in index_list:\n",
    "            final_list.append(scores_e[j])\n",
    "        return final_list\n",
    "\n",
    "def graphing_single_word_finder(word1,word2='',mode='single'):\n",
    "    graphing_data=single_word_finder(word1,'','single')\n",
    "    graphing_data=pd.Series(graphing_data)\n",
    "    score_list=[]\n",
    "    non_word1_list=[]\n",
    "    for i,v in graphing_data.iteritems():\n",
    "        if(graphing_data[i][1][0][0]!=word1):\n",
    "            non_word1_list.append(graphing_data[i][1][0][0])\n",
    "        elif(graphing_data[i][1][0][1])!=word1:\n",
    "            non_word1_list.append(graphing_data[i][1][0][1])\n",
    "        score_list.append(graphing_data[i][1][1])\n",
    "    final_graphing=pd.concat([pd.Series(non_word1_list),pd.Series(score_list)],axis=1)\n",
    "    final_graphing.columns=['Word','PMI_Score']\n",
    "    sns.mpl.rc(\"figure\", figsize=(9,4))\n",
    "    word_graph=sns.stripplot(x=\"Word\", y=\"PMI_Score\", data=final_graphing, size = 8)\n",
    "    loc, labels = plt.xticks()\n",
    "    word_graph.set_xticklabels(labels, rotation=90)\n",
    "    return(final_graphing)\n",
    "\n",
    "def graphing_labels(word1,word2='',mode='single'):\n",
    "    graphing_data=single_word_finder(word1,'','single')\n",
    "    graphing_data=pd.Series(graphing_data)\n",
    "    score_list=[]\n",
    "    non_word1_list=[]\n",
    "    for i,v in graphing_data.iteritems():\n",
    "        if(graphing_data[i][1][0][0]!=word1):\n",
    "            non_word1_list.append(graphing_data[i][1][0][0])\n",
    "        elif(graphing_data[i][1][0][1])!=word1:\n",
    "            non_word1_list.append(graphing_data[i][1][0][1])\n",
    "        score_list.append(graphing_data[i][1][1])\n",
    "    final_graphing=pd.concat([pd.Series(non_word1_list),pd.Series(score_list)],axis=1)\n",
    "    final_graphing.columns=['Word','PMI_Score']\n",
    "    return(final_graphing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Setting up table generator example\n",
    "def generate_table(dataframe, maxrows=10):\n",
    "    return html.Table(\n",
    "        # Header\n",
    "        [html.Tr([html.Th(col) for col in dataframe.columns])] +\n",
    "\n",
    "        # Body\n",
    "        [html.Tr([\n",
    "            html.Td(dataframe.iloc[i][col]) for col in dataframe.columns\n",
    "        ]) for i in range(min(len(dataframe), maxrows))]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Text Example\n",
    "\n",
    "example_text='''\n",
    "## This is where we would write an intro.\n",
    "\n",
    "Maybe something about how to use the dashboard, or how to get it to run.\n",
    "Explanation of scores, things like that.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IncorrectTypeException",
     "evalue": "The input argument `<dash.dependencies.Input instance at 0x0000000020106348>` is not a list of `dash.dependencies.Input`s.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mIncorrectTypeException\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7d57a943f198>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;31m#Testing on the table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m @app.callback(dash.dependencies.Output('table','children'),\n\u001b[1;32m---> 67\u001b[1;33m              \u001b[0mdash\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'output-container-date-selector'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'children'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m              )\n\u001b[0;32m     69\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mupdate_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\583185\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py27\\lib\\site-packages\\dash\\dash.pyc\u001b[0m in \u001b[0;36mcallback\u001b[1;34m(self, output, inputs, state, events)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;31m# relationships\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         callback_id = '{}.{}'.format(\n",
      "\u001b[1;32mC:\\Users\\583185\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py27\\lib\\site-packages\\dash\\dash.pyc\u001b[0m in \u001b[0;36m_validate_callback\u001b[1;34m(self, output, inputs, state, events)\u001b[0m\n\u001b[0;32m    352\u001b[0m                     \u001b[1;34m'The {} argument `{}` is '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                     'not a list of `dash.dependencies.{}`s.'.format(\n\u001b[1;32m--> 354\u001b[1;33m                         \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m                     ))\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIncorrectTypeException\u001b[0m: The input argument `<dash.dependencies.Input instance at 0x0000000020106348>` is not a list of `dash.dependencies.Input`s."
     ]
    }
   ],
   "source": [
    "##Setting up a test environment\n",
    "\n",
    "\n",
    "\n",
    "app=dash.Dash()\n",
    "\n",
    "\n",
    "\n",
    "colors={\n",
    "    'background': '#111111',\n",
    "    'text': '#7FDBFF'\n",
    "}\n",
    "\n",
    "app.layout=html.Div(children=\n",
    "    [html.H1(children='This is the title pane',\n",
    "             style={\n",
    "                 'textAlign': 'center', 'color':colors['text']}   ),\n",
    "    dcc.Markdown(children=example_text), \n",
    "    html.H2(children='Please use these inputs to customize your report',\n",
    "            style={\n",
    "                 'textAlign': 'center', 'color':colors['text']} ),\n",
    "    dcc.DatePickerRange(\n",
    "        id='date_selector',\n",
    "        min_date_allowed=dt(2017,1,1),\n",
    "        end_date=dt.today()),\n",
    "#Need to work on spacing here and then figure out how to use them as arguments for all of the functions  \n",
    "    html.Label('First word finder'),\n",
    "    dcc.Input(\n",
    "        id='first_word_finder',\n",
    "        value='',\n",
    "        type='text'),\n",
    "    html.Label('Second word finder'),\n",
    "    dcc.Input(value='If you would like to find the intersection of the first word and another please enter here',type='text'),\n",
    "    ##Try to build the graph here \n",
    "    dcc.Graph(\n",
    "        id='test_graph',  \n",
    "    ),\n",
    "     html.H4(id='table',children='This is the Connect report for the specified time'),\n",
    "      generate_table(final_report,10),\n",
    "     \n",
    "     html.Div(id='output-container-date-selector',style={'display': 'none'}),\n",
    "     html.Div(id='output-container-top-words',style={'display':'none'}),\n",
    "     html.Div(id=\"output-container-scored\",style={'display':'none'})\n",
    "     \n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#Need to move things that are setup/dependent on reactive inputs here into here\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('output-container-date-selector','children'),\n",
    "[dash.dependencies.Input('date_selector','start_date'),\n",
    " dash.dependencies.Input('date_selector','end_date')]\n",
    ")\n",
    "##going to need to do this in a bunch of different functions?\n",
    "def update_report(final_report,input1,input2):\n",
    "    if(input1==\"2017-01-01\" and input2== pd.to_datetime('today')):\n",
    "        final_report_reactive=final_report\n",
    "    else:\n",
    "        start=pd.to_datetime(input1, utc=False)\n",
    "        end=pd.to_datetime(input2, utc=False)\n",
    "        final_report_reactive=final_report[(final_report['Created Date'] > start) & (final_report['Created Date']< end)]   \n",
    "    return(final_report_reactive.to_json())\n",
    "#Testing on the table\n",
    "@app.callback(dash.dependencies.Output('table','children'),\n",
    "             dash.dependencies.Input('output-container-date-selector','children')\n",
    "             )\n",
    "def update_table(input1):\n",
    "    generate_table(input1,10)\n",
    "\n",
    "# @app.callback(dash.dependencies.Output('output-container-top-words','children'),\n",
    "#              dash.dependencies.Input('output-container-date-selector','children')\n",
    "#              )\n",
    "# def update_top_words(input):\n",
    "#     top_words_reactive=single_day_tracker(input)\n",
    "#     return(top_words_reactive.to_json())\n",
    "\n",
    "# @app.callback(dash.dependencies.Output('output-container-scored','children'),\n",
    "#             [dash.dependencies.Input('output-container-top-words','children'),\n",
    "#               dash.dependencies.Input('output-container-date-selector','children')]\n",
    "#              )\n",
    "# def update_scores(input1): \n",
    "# #Bigrams/collocation scoring\n",
    "#     bigram_measures=nltk.collocations.BigramAssocMeasures()\n",
    "#     finder_2=BigramCollocationFinder.from_documents(input2['tokens'])\n",
    "#     score_collocation_2=finder_2.nbest(bigram_measures.pmi,5)\n",
    "\n",
    "#     scored = finder_2.score_ngrams(bigram_measures.pmi)\n",
    "#     sorted_scored_reactive=sorted(bigram for bigram, score in scored)\n",
    "#     return(sorted_scored_reactive)\n",
    "\n",
    "\n",
    "# @app.callback(\n",
    "#     dash.dependencies.Output('test_graph','figure'),\n",
    "#     [dash.dependencies.Input('first_word_finder','value'),\n",
    "#     dash.dependencies.Input('output-container-scored')]\n",
    "# )\n",
    "\n",
    "# def update_graph(input1,input2):\n",
    "\n",
    "#     pmi_score=graphing_single_word_finder(input1,'',mode='single')\n",
    "#     g_labels=graphing_labels(input2,'',mode='single')\n",
    "#     g_labels=g_labels['Word'].tolist()\n",
    "#     return{\n",
    "#             'data': [\n",
    "#                 go.Scatter(\n",
    "#                 x=pmi_score['Word'],\n",
    "#                 y=pmi_score['PMI_Score'],\n",
    "#                 mode='markers',\n",
    "#                     marker=dict(\n",
    "#                     color=range(0,len(pmi_score)),\n",
    "#                     cmin=0,\n",
    "#                     cmax=28,\n",
    "#                     colorscale='Jet'\n",
    "#                 )\n",
    "#                 )\n",
    "#                 ],\n",
    "#             'layout':go.Layout(\n",
    "#                 xaxis={'title':'PMI for Searched words','ticktext':g_labels}\n",
    "#                 )\n",
    "#    }\n",
    "\n",
    "\n",
    "show_app(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2017, 11, 24, 12, 2, 36, 284000),\n",
       " datetime.datetime(2017, 11, 24, 12, 2, 36, 284000)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list=[pd.datetime.today()]*2\n",
    "test_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
